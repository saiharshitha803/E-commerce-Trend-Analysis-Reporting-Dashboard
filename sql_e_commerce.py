# -*- coding: utf-8 -*-
"""SQL E-commerce.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SIIEjCR6Zzev5BC_QRaX65vWbZcZ2NSu
"""

import pandas as pd

# Load the dataset
df = pd.read_csv('/content/data.csv', encoding='cp1252')

# --- 1. Data Cleaning (Handling Missing Values and Anomalies) ---

# Drop rows with missing CustomerID or Description (essential for customer analysis)
df_cleaned = df.dropna(subset=['CustomerID', 'Description']).copy()

# Filter for successful transactions:
# - Quantity must be positive (removes returns/cancellations)
# - UnitPrice must be positive (removes free items/errors)
df_cleaned = df_cleaned[
    (df_cleaned['Quantity'] > 0) & (df_cleaned['UnitPrice'] > 0)
].reset_index(drop=True)

# --- 2. Feature Engineering ---

# Calculate the line-item sales/revenue
df_cleaned['Sales'] = df_cleaned['Quantity'] * df_cleaned['UnitPrice']

# --- 3. Data Type Refinement ---

# Convert InvoiceDate to datetime
df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])

# Convert CustomerID to integer (since all NaNs are removed)
df_cleaned['CustomerID'] = df_cleaned['CustomerID'].astype(int)

# --- 4. Save the Result ---

# Save the final cleaned DataFrame to a new CSV file
# This file is ready for import into your SQL database
df_cleaned.to_csv('processed_data_for_sql.csv', index=False)

print("Pre-processed dataset saved as 'processed_data_for_sql.csv'.")
print(f"Final records count: {len(df_cleaned)}")

import pandas as pd

# Load the dataset
df = pd.read_csv('/content/data.csv', encoding='cp1252')

print(f"Original Data Size: {len(df)} rows")

# Drop rows where CustomerID or Description is missing (NaN)
df_cleaned = df.dropna(subset=['CustomerID', 'Description']).copy()

# 135,080 rows for CustomerID and 1,454 rows for Description were removed in total
print(f"Size after dropping missing values: {len(df_cleaned)} rows")

# Filter out non-positive quantities (returns/cancellations)
# and non-positive unit prices (free items or errors)
df_cleaned = df_cleaned[
    (df_cleaned['Quantity'] > 0) & (df_cleaned['UnitPrice'] > 0)
].reset_index(drop=True)

# 10,624 rows for Quantity and 2,517 rows for UnitPrice were removed
print(f"Size after filtering anomalies: {len(df_cleaned)} rows")

# Calculate the total sales/revenue for the line item
df_cleaned['Sales'] = df_cleaned['Quantity'] * df_cleaned['UnitPrice']

# Convert InvoiceDate to the proper datetime format
df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])

# Convert CustomerID from float to integer (since missing values are gone)
df_cleaned['CustomerID'] = df_cleaned['CustomerID'].astype(int)

# Save the final cleaned DataFrame
df_cleaned.to_csv('processed_data_for_sql_final.csv', index=False)

print("\nPreprocessing Complete!")
print(f"Final Data Size: {len(df_cleaned)} rows")
print("File saved as 'processed_data_for_sql_final.csv'")

import pandas as pd

# Load the dataset
df = pd.read_csv('/content/processed_data_for_sql_final.csv')
df.head(10)

import pandas as pd
import sqlite3
from io import StringIO

# 1. Load the data
df = pd.read_csv('processed_data_for_sql_final.csv')

# 2. Create an in-memory SQLite database connection
conn = sqlite3.connect(':memory:')

# 3. Write the DataFrame to an SQL table named 'SalesData'
# 'if_exists='replace'' drops the table if it already exists
df.to_sql('SalesData', conn, if_exists='replace', index=False)

print("Data loaded into SQLite database successfully. You can now run SQL queries using the connection object 'conn'.")

# The triple quote opens the string
# monthly sales trend
mom_growth_querys = """
SELECT
    STRFTIME('%Y', InvoiceDate) AS SalesYear,
    STRFTIME('%m', InvoiceDate) AS SalesMonth,
    SUM(Sales) AS TotalSales
FROM
    SalesData
GROUP BY
    SalesYear, SalesMonth
ORDER BY
    SalesYear, SalesMonth;
"""
# The code continues here
results_df = pd.read_sql(mom_growth_querys, conn)
# ...
print(results_df)
import matplotlib.pyplot as plt

# Assuming df1 holds the results of Query 1
plt.figure(figsize=(12, 6))

# Create a combined period column for the X-axis
results_df['Period'] = results_df['SalesYear'] + '-' + results_df['SalesMonth']

plt.plot(results_df['Period'], results_df['TotalSales'], marker='o', linestyle='-', color='skyblue')

# Add titles and labels
plt.title('Monthly Sales Trend', fontsize=16)
plt.xlabel('Sales Period', fontsize=12)
plt.ylabel('Total Sales (USD)', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)

# Rotate X-axis labels to prevent overlap (especially for months)
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Save the plot
plt.savefig('monthly_sales_trend.png')
# plt.show() # Uncomment if running locally

# avg order value trend
# Assuming the 'conn' object from the SQLite setup is still active

aov_trend_query = """
WITH InvoiceSales AS (
    -- Calculate total sales for each unique invoice
    SELECT
        InvoiceNo,
        InvoiceDate,
        SUM(Sales) AS InvoiceTotal
    FROM
        SalesData
    GROUP BY
        InvoiceNo, InvoiceDate
)
SELECT
    STRFTIME('%Y', InvoiceDate) AS SalesYear,
    STRFTIME('%m', InvoiceDate) AS SalesMonth,
    AVG(InvoiceTotal) AS AvgOrderValue
FROM
    InvoiceSales
GROUP BY
    SalesYear, SalesMonth
ORDER BY
    SalesYear, SalesMonth;
"""

# Execute the query and store the results in a new DataFrame
aov_df = pd.read_sql(aov_trend_query, conn)

print("Average Order Value (AOV) Trend Results:")
print(aov_df)

# monthover month sales growth
# Assuming the 'conn' object from the SQLite setup is still active
mom_growth_query = """
WITH MonthlySales AS (
    -- Step 1: Calculate Total Sales per Month
    SELECT
        STRFTIME('%Y-%m', InvoiceDate) AS SalesPeriod,
        SUM(Sales) AS CurrentSales
    FROM
        SalesData
    GROUP BY
        SalesPeriod
)
SELECT
    SalesPeriod,
    CurrentSales,
    -- Get sales from the previous month
    LAG(CurrentSales, 1) OVER (ORDER BY SalesPeriod) AS PreviousSales,
    -- Calculate MoM Growth Percentage
    (CurrentSales - LAG(CurrentSales, 1) OVER (ORDER BY SalesPeriod)) * 100.0 / LAG(CurrentSales, 1) OVER (ORDER BY SalesPeriod) AS MoM_Growth_Percent
FROM
    MonthlySales
ORDER BY
    SalesPeriod;
"""

# Execute the query and store the results in a new DataFrame
mom_df = pd.read_sql(mom_growth_query, conn)

print("Month-Over-Month Sales Growth Results:")
print(mom_df)
import matplotlib.pyplot as plt

# Assuming df3 holds the results of Query 3
plt.figure(figsize=(12, 6))

# Filter out the first period which has a NULL MoM_Growth_Percent
df_plot = mom_df.dropna(subset=['MoM_Growth_Percent']).copy()

# Define colors based on growth direction
colors = ['green' if x >= 0 else 'red' for x in df_plot['MoM_Growth_Percent']]

plt.bar(df_plot['SalesPeriod'], df_plot['MoM_Growth_Percent'], color=colors)

# Add titles and labels
plt.title('Month-Over-Month Sales Growth Percentage', fontsize=16)
plt.xlabel('Sales Period', fontsize=12)
plt.ylabel('MoM Growth (%)', fontsize=12)
plt.axhline(0, color='black', linewidth=0.8) # Add a line at 0%
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Save the plot
plt.savefig('mom_growth_bar_chart.png')
# plt.show() # Uncomment if running locally

# cummulative sales trend
# Assuming the 'conn' object from the SQLite setup is still active

import pandas as pd # Ensure pandas is imported

cumulative_sales_query = """
SELECT
    STRFTIME('%Y-%m', InvoiceDate) AS SalesPeriod,
    SUM(Sales) AS MonthlySales,
    -- Calculate the running sum of sales ordered by time period
    SUM(SUM(Sales)) OVER (ORDER BY STRFTIME('%Y-%m', InvoiceDate)) AS CumulativeSales
FROM
    SalesData
GROUP BY
    SalesPeriod
ORDER BY
    SalesPeriod;
"""

# Execute the query and store the results in a new DataFrame
cumulative_df = pd.read_sql(cumulative_sales_query, conn)

print("Cumulative Sales Trend (Running Total) Results:")
print(cumulative_df)

import matplotlib.pyplot as plt

# Assuming df4 holds the results of Query 4
plt.figure(figsize=(12, 6))

plt.plot(cumulative_df['SalesPeriod'], cumulative_df['CumulativeSales'], marker='o', linestyle='-', color='purple')

# Add titles and labels
plt.title('Cumulative Sales (Running Total)', fontsize=16)
plt.xlabel('Sales Period', fontsize=12)
plt.ylabel('Cumulative Sales (USD)', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)

plt.xticks(rotation=45, ha='right', fontsize=10)
plt.tight_layout()

# Save the plot
plt.savefig('cumulative_sales_trend.png')
# plt.show() # Uncomment if running locally

# year over year
# Assuming the 'conn' object from the SQLite setup is still active

import pandas as pd # Ensure pandas is imported

yoy_growth_query = """
WITH MonthlySales AS (
    SELECT
        STRFTIME('%Y', InvoiceDate) AS SalesYear,
        STRFTIME('%m', InvoiceDate) AS SalesMonth,
        SUM(Sales) AS CurrentSales
    FROM
        SalesData
    GROUP BY
        SalesYear, SalesMonth
)
SELECT
    SalesYear,
    SalesMonth,
    CurrentSales,
    -- Get the sales from the same month 1 year ago (12 periods back)
    LAG(CurrentSales, 12) OVER (ORDER BY SalesYear, SalesMonth) AS PriorYearSales,
    -- Calculate YoY Growth Percentage
    (CurrentSales - LAG(CurrentSales, 12) OVER (ORDER BY SalesYear, SalesMonth)) * 100.0 / LAG(CurrentSales, 12) OVER (ORDER BY SalesYear, SalesMonth) AS YoY_Growth_Percent
FROM
    MonthlySales
ORDER BY
    SalesYear, SalesMonth;
"""

# Execute the query and store the results in a new DataFrame
yoy_df = pd.read_sql(yoy_growth_query, conn)

print("Year-Over-Year (YoY) Sales Growth Results:")
print(yoy_df)

# Sales Velocity (Average Daily Sales per Month)
# Assuming the 'conn' object from the SQLite setup is still active

import pandas as pd # Ensure pandas is imported

sales_velocity_query = """
WITH DailySales AS (
    -- 1. Calculate total sales for each distinct day
    SELECT
        DATE(InvoiceDate) AS SalesDate,
        STRFTIME('%Y-%m', InvoiceDate) AS SalesPeriod,
        SUM(Sales) AS DailyRevenue
    FROM
        SalesData
    GROUP BY
        SalesDate
)
SELECT
    SalesPeriod,
    -- 2. Calculate the average of those daily revenues for the period
    AVG(DailyRevenue) AS AvgDailySales
FROM
    DailySales
GROUP BY
    SalesPeriod
ORDER BY
    SalesPeriod;
"""

# Execute the query and store the results in a new DataFrame
velocity_df = pd.read_sql(sales_velocity_query, conn)

print("Sales Velocity (Average Daily Sales per Month) Results:")
print(velocity_df)

# Busiest Day of the Week and Hour of the Day!
# Assuming the 'conn' object from the SQLite setup is still active

import pandas as pd # Ensure pandas is imported

busiest_time_query = """
SELECT
    -- %w returns the day of the week (0=Sunday, 1=Monday, ..., 6=Saturday)
    STRFTIME('%w', InvoiceDate) AS DayOfWeekIndex,
    CASE STRFTIME('%w', InvoiceDate)
        WHEN '0' THEN 'Sunday'
        WHEN '1' THEN 'Monday'
        WHEN '2' THEN 'Tuesday'
        WHEN '3' THEN 'Wednesday'
        WHEN '4' THEN 'Thursday'
        WHEN '5' THEN 'Friday'
        WHEN '6' THEN 'Saturday'
    END AS DayOfWeekName,
    STRFTIME('%H', InvoiceDate) AS SalesHour,
    SUM(Quantity) AS TotalQuantitySold
FROM
    SalesData
GROUP BY
    DayOfWeekIndex, SalesHour
ORDER BY
    TotalQuantitySold DESC;
"""

# Execute the query and store the results in a new DataFrame
busiest_time_df = pd.read_sql(busiest_time_query, conn)

print("Busiest Day of Week and Hour Results:")
print(busiest_time_df)

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns # Seaborn is excellent for heatmaps

# Assuming df7 holds the results of Query 7

# Map DayOfWeekIndex (0=Sunday to 6=Saturday) to proper names for ordering
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']

# 1. Pivot the data for the heatmap: Rows=DayOfWeekName, Columns=SalesHour, Values=TotalQuantitySold
pivot_df = busiest_time_df.pivot_table(
    index='DayOfWeekName',
    columns='SalesHour',
    values='TotalQuantitySold'
)

# 2. Re-index the pivot table to enforce correct day order
pivot_df = pivot_df.reindex(day_order)

# 3. Create the heatmap
plt.figure(figsize=(14, 7))
sns.heatmap(
    pivot_df,
    annot=True,        # Show the quantity values on the cells
    fmt='.0f',         # Format values as integers
    cmap='viridis',    # Color scheme
    linewidths=.5,     # Add lines between cells
    cbar_kws={'label': 'Total Quantity Sold'}
)

plt.title('Operational Hotspots: Total Quantity Sold by Day and Hour', fontsize=16)
plt.xlabel('Hour of Day (24-Hour Clock)', fontsize=12)
plt.ylabel('Day of Week', fontsize=12)
plt.yticks(rotation=0)
plt.tight_layout()

# Save the plot
plt.savefig('busiest_time_heatmap.png')
# plt.show() # Uncomment if running locally

"""
This is an excellent set of analyses! Since the SQL queries are designed to run
on the 2010-2011 e-commerce dataset, I will provide a **concrete analysis** for
each statement, explaining the typical findings and the crucial business decisions
that can be made from those results.

## I. Core Trends and Value

### 1. Monthly Sales Trend (Total Revenue)
This analysis provides the most straightforward view of the business's financial performance.
* **Expected Finding:** A strong **seasonal spike** in November and December of both 2010 and 2011,
 with December 2011 likely representing the absolute peak month due to holiday shopping. Conversely,
 sales often dip significantly in January and February.
* **Business Implication:** Confirms peak seasons and helps with **annual budgeting**
 and **inventory forecasting**. The company should ensure maximum staffing and stock levels
 leading into Q4, while planning cost-saving or promotional activities during slower periods.

### 2. Average Order Value (AOV) Trend
AOV is a key health metric, tracking the average dollar value per transaction.
* **Expected Finding:** AOV might remain relatively flat or show slight increases over the year,
 often peaking just before major gift-buying holidays (e.g., November). A low or declining AOV would be a red flag.
* **Business Implication:** If AOV is strong, the marketing strategy is successful. If AOV is low,
 the business should implement strategies like **free shipping thresholds** ("Spend \$50 more for free shipping")
  or **bundle deals** to instantly boost the transaction value.

### 6. Sales Velocity (Average Daily Sales per Month)
This metric normalizes sales across months of different lengths (28, 30, or 31 days).
* **Expected Finding:** The highest average daily sales will typically align with the peak months (November/December).
 The velocity trend is often smoother than the Total Sales trend because it filters out noise from month length.
* **Business Implication:** This is the most accurate measure of sales *speed*. It helps leadership understand
true operational pressure and confirms whether growth is driven by actual demand or merely by having more selling days
 (e.g., comparing a 31-day month to a 30-day month).

***

## II. Growth and Momentum Dynamics

### 3. Month-Over-Month (MoM) Growth
This provides an immediate measure of business momentum, showing month-to-month volatility.
* **Expected Finding:** Results will be volatile. You'll see massive **negative drops** from December to January
 (post-holiday slump) and possibly large **positive spikes** in late summer/fall as customers prepare for holidays.
* **Business Implication:** MoM is best for short-term operational steering. If you see two consecutive months of
negative MoM growth outside of a known seasonal slump, it signals an immediate need for an aggressive sales campaign
 or strategic intervention.

### 4. Cumulative Sales Trend
This is the ultimate long-term health check, showing the total revenue generated since the starting point.
* **Expected Finding:** A continuously rising, smooth line that accelerates during high-sales periods (Q4).
The final value represents the total revenue for the entire period analyzed.
* **Business Implication:** This chart is excellent for **investor relations** or executive presentations,
 visualizing the overall **scale and historical trajectory** of the business. The steepness of the curve
 indicates the rate of growth.

### 5. Year-Over-Year (YoY) Growth
This is the single most important metric for determining **sustainable business health**.
* **Expected Finding:** For a growing business, all YoY numbers should be positive. If December 2011
sales are up 40% compared to December 2010 sales, that confirms strong growth that is not just seasonal luck.
 Negative YoY growth is a serious indicator of market loss.
* **Business Implication:** This drives high-level strategic planning. If the YoY growth for a particular
month is lagging, it suggests that last year's strategy was more effective, prompting an analysis of past campaigns,
 product launches, or pricing structures.

## III. Operational Efficiency

### 7. Busiest Day of the Week / Hour of the Day
This is pure operational insight, tracking the volume of units sold.
* **Expected Finding:** Sales are likely highest on weekdays (Tuesday, Wednesday, Thursday) and
 drop off on weekends. The peak hours are typically late morning/midday (e.g., 10:00 AM to 3:00 PM),
 with few sales outside of standard business hours (e.g., after 8:00 PM).
* **Business Implication:** This data is critical for **staffing the fulfillment center and customer support**.
It dictates when hourly staff should be scheduled, ensuring maximum coverage during peak volume times to maintain high
 customer satisfaction and efficient shipping operations.
"""

import pandas as pd
import sqlite3
import warnings
from io import StringIO
!pip install xlsxwriter
# Suppress warnings
warnings.filterwarnings('ignore')

# --- 1. SETUP & SQL EXECUTION (Re-run all 7 queries to define DataFrames) ---

# Load data and setup SQLite connection (assuming 'processed_data_for_sql_final.csv' is present)
df = pd.read_csv('processed_data_for_sql_final.csv')
conn = sqlite3.connect(':memory:')
df.to_sql('SalesData', conn, if_exists='replace', index=False)

# Define all 7 queries (abbreviated for compactness)
mom_growth_querys = """
SELECT
    STRFTIME('%Y', InvoiceDate) AS SalesYear,
    STRFTIME('%m', InvoiceDate) AS SalesMonth,
    SUM(Sales) AS TotalSales
FROM
    SalesData
GROUP BY
    SalesYear, SalesMonth
ORDER BY
    SalesYear, SalesMonth;
"""

aov_trend_query = """
WITH InvoiceSales AS (
    -- Calculate total sales for each unique invoice
    SELECT
        InvoiceNo,
        InvoiceDate,
        SUM(Sales) AS InvoiceTotal
    FROM
        SalesData
    GROUP BY
        InvoiceNo, InvoiceDate
)
SELECT
    STRFTIME('%Y', InvoiceDate) AS SalesYear,
    STRFTIME('%m', InvoiceDate) AS SalesMonth,
    AVG(InvoiceTotal) AS AvgOrderValue
FROM
    InvoiceSales
GROUP BY
    SalesYear, SalesMonth
ORDER BY
    SalesYear, SalesMonth;
"""
mom_growth_query = """
WITH MonthlySales AS (
    -- Step 1: Calculate Total Sales per Month
    SELECT
        STRFTIME('%Y-%m', InvoiceDate) AS SalesPeriod,
        SUM(Sales) AS CurrentSales
    FROM
        SalesData
    GROUP BY
        SalesPeriod
)
SELECT
    SalesPeriod,
    CurrentSales,
    -- Get sales from the previous month
    LAG(CurrentSales, 1) OVER (ORDER BY SalesPeriod) AS PreviousSales,
    -- Calculate MoM Growth Percentage
    (CurrentSales - LAG(CurrentSales, 1) OVER (ORDER BY SalesPeriod)) * 100.0 / LAG(CurrentSales, 1) OVER (ORDER BY SalesPeriod) AS MoM_Growth_Percent
FROM
    MonthlySales
ORDER BY
    SalesPeriod;
"""
cumulative_sales_query = """
SELECT
    STRFTIME('%Y-%m', InvoiceDate) AS SalesPeriod,
    SUM(Sales) AS MonthlySales,
    -- Calculate the running sum of sales ordered by time period
    SUM(SUM(Sales)) OVER (ORDER BY STRFTIME('%Y-%m', InvoiceDate)) AS CumulativeSales
FROM
    SalesData
GROUP BY
    SalesPeriod
ORDER BY
    SalesPeriod;
"""
yoy_growth_query = """
WITH MonthlySales AS (
    SELECT
        STRFTIME('%Y', InvoiceDate) AS SalesYear,
        STRFTIME('%m', InvoiceDate) AS SalesMonth,
        SUM(Sales) AS CurrentSales
    FROM
        SalesData
    GROUP BY
        SalesYear, SalesMonth
)
SELECT
    SalesYear,
    SalesMonth,
    CurrentSales,
    -- Get the sales from the same month 1 year ago (12 periods back)
    LAG(CurrentSales, 12) OVER (ORDER BY SalesYear, SalesMonth) AS PriorYearSales,
    -- Calculate YoY Growth Percentage
    (CurrentSales - LAG(CurrentSales, 12) OVER (ORDER BY SalesYear, SalesMonth)) * 100.0 / LAG(CurrentSales, 12) OVER (ORDER BY SalesYear, SalesMonth) AS YoY_Growth_Percent
FROM
    MonthlySales
ORDER BY
    SalesYear, SalesMonth;
"""

sales_velocity_query = """
WITH DailySales AS (
    -- 1. Calculate total sales for each distinct day
    SELECT
        DATE(InvoiceDate) AS SalesDate,
        STRFTIME('%Y-%m', InvoiceDate) AS SalesPeriod,
        SUM(Sales) AS DailyRevenue
    FROM
        SalesData
    GROUP BY
        SalesDate
)
SELECT
    SalesPeriod,
    -- 2. Calculate the average of those daily revenues for the period
    AVG(DailyRevenue) AS AvgDailySales
FROM
    DailySales
GROUP BY
    SalesPeriod
ORDER BY
    SalesPeriod;
"""

busiest_time_query = """
SELECT
    -- %w returns the day of the week (0=Sunday, 1=Monday, ..., 6=Saturday)
    STRFTIME('%w', InvoiceDate) AS DayOfWeekIndex,
    CASE STRFTIME('%w', InvoiceDate)
        WHEN '0' THEN 'Sunday'
        WHEN '1' THEN 'Monday'
        WHEN '2' THEN 'Tuesday'
        WHEN '3' THEN 'Wednesday'
        WHEN '4' THEN 'Thursday'
        WHEN '5' THEN 'Friday'
        WHEN '6' THEN 'Saturday'
    END AS DayOfWeekName,
    STRFTIME('%H', InvoiceDate) AS SalesHour,
    SUM(Quantity) AS TotalQuantitySold
FROM
    SalesData
GROUP BY
    DayOfWeekIndex, SalesHour
ORDER BY
    TotalQuantitySold DESC;
"""
# Execute all queries
results_df = pd.read_sql(mom_growth_querys, conn)
aov_df = pd.read_sql(aov_trend_query, conn)
mom_df= pd.read_sql(mom_growth_query, conn)
cumulative_df = pd.read_sql(cumulative_sales_query , conn)
yoy_df = pd.read_sql(yoy_growth_query, conn)
velocity_df = pd.read_sql(sales_velocity_query, conn)
busiest_time_df = pd.read_sql(busiest_time_query, conn)

conn.close()

# --- 2. EXPORT TO EXCEL ---

output_file = 'Sales_Trend_Analysis.xlsx'

with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
    results_df.to_excel(writer, sheet_name='1_Monthly Sales', index=False)
    aov_df.to_excel(writer, sheet_name='2_AOV Trend', index=False)
    mom_df.to_excel(writer, sheet_name='3_MoM Growth', index=False)
    cumulative_df.to_excel(writer, sheet_name='4_Cumulative Sales', index=False)
    yoy_df .to_excel(writer, sheet_name='5_YoY Growth', index=False)
    velocity_df.to_excel(writer, sheet_name='6_Sales Velocity', index=False)
    busiest_time_df.to_excel(writer, sheet_name='7_Busiest Time', index=False)

print(f"\nSuccessfully exported all 7 results to {output_file}. Please download this file from your Colab files panel.")

"""E-commerce Trend Analysis & Reporting Dashboard

Tools: Python (Pandas), SQL (SQLite, Advanced Window Functions:
 LAG), Google Colab, MS Excel (Pivot Tables, Data Visualization).

Action: Extracted and transformed raw sales data using advanced SQL queries
 (e.g., LAG for MoM/YoY calculations) within Python. Exported seven separate,
 clean datasets to a multi-sheet Excel workbook.

Result: Constructed a dynamic, interactive Excel Dashboard featuring Total Sales,
 AOV Trend, and a Time-of-Day Sales Heatmap, enabling stakeholders to track growth,
 identify seasonality, and optimize operational scheduling based on data-driven insights."""

